{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset in a matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X is stored in a h5 file. \n",
    "There are 4400 different samples. \n",
    "Each sample is made of 8 concatenated signals.\n",
    "Each signal is 90 sec window, sampled with a 100Hz frequency (ie 9000 values.)\n",
    "(so size of one sample is 9000*8= 72000 values)\n",
    "\n",
    "\n",
    "- 0: sample index\n",
    "- 1: subject index\n",
    "- 2 to 9001: Abdominal belt\n",
    "- 9002 to 18001: Airflow\n",
    "- 18002 to 27001: PPG (Photoplethysmogram)\n",
    "- 27002 to 36001: Thoracic belt\n",
    "- 36002 to 45001: Snoring indicator\n",
    "- 45002 to 54001: SPO2\n",
    "- 54002 to 63001: C4-A1\n",
    "- 63002 to 72001:O2-A1\n",
    "\"\"\"\n",
    "\n",
    "X = h5py.File('X_train.h5', 'r')  \n",
    "print(X.keys())\n",
    "\n",
    "X = X['data'][:] # convert h5 file to a numpy array\n",
    "X = X[:,2:] #remove patient id and index (useless)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the sleeping apneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is, for each of the 4400 samples,  a boolean mask of length 90 sec. \"1\" means sleeping apnea. \"0\" means normal sleep\n",
    "\n",
    "y = pd.read_csv('y_train.csv')\n",
    "y = y.iloc[:,1:] #remove the index column (useless)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns               #visualising sleeping apneas spread\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(y,cbar=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping X for the 1d convolutional network : size (4400, 8 ,9) to preserve temporal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshape = np.zeros( (4400, 8, 9000) )\n",
    "\n",
    "for i in range(4400):\n",
    "    X_reshape[i] = X[:,i].reshape(8, 9000)\n",
    "\n",
    "X_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing each row of each sample. The 8 signals differ in range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BEFORE NORMALIZATION \"\"\"\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(X_reshape[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "def normalisation( X ):\n",
    "    \n",
    "    \"\"\" gets a matrix and returns this matrix normalized on per ROW \"\"\"\n",
    "    \n",
    "    X = X.T\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X.T\n",
    "\n",
    "X_norm = np.zeros( (4400, 8, 9000) )\n",
    "\n",
    "for i in range (4400) :\n",
    "    X_norm[i,:,:] = normalisation( X_reshape[i,:,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" AFTER NORMALIZATION \"\"\"\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(X_norm[1,1,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_norm, y, test_size=0.2, random_state=0 )  #splitting the dataset between train set and test set.\n",
    "print( X_train.shape )\n",
    "print( y_train.shape )\n",
    "print( X_test.shape )\n",
    "print( y_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([    \n",
    "    \n",
    "#BASE                                          \n",
    "    layers.Conv1D(filters=64, kernel_size=8 , strides=1 , padding='same', input_shape=[8, 9000]), \n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Conv1D(filters=128, kernel_size=5 , strides=1 , padding='same'),  \n",
    "    layers.Activation('relu'),\n",
    "\n",
    "\n",
    "#HEAD\n",
    "    layers.Flatten(), \n",
    "    layers.Dense(90, activation='sigmoid') \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function : cross entropy on a vector? (and for 4400 samples?)\n",
    "\n",
    "model.compile( optimizer ='adam', loss ='binary_crossentropy', metrics =['binary_accuracy'] ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the network\n",
    "\n",
    "record = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data =( X_test, y_test ),\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting learning curves\n",
    "\n",
    "history_df = pd.DataFrame( record.history )\n",
    "\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot() \n",
    "\n",
    "print((\"Best Validation Loss: {}\"  + \"Best Validation accuracy: {}\").format(history_df['val_loss'].min(), \n",
    "            history_df['val_binary_accuracy'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm[18:19,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_example = model.predict( X_norm[18:19,:,:] )\n",
    "print( pred_example.shape )\n",
    "plt.plot(pred_example.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same preprocessing on X_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true= h5py.File('X_test.h5', 'r') # loading X ground truth set\n",
    "X_true=X_true['data'][:] \n",
    "X_true=X_true[:,2:]\n",
    "X_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true = X_true.T\n",
    "X_true.shape\n",
    "\n",
    "X_true_reshape = np.zeros( (4400, 8, 9000) )\n",
    "\n",
    "for i in range(4400):\n",
    "    X_true_reshape[i] = X_true[:,i].reshape(8, 9000)\n",
    "\n",
    "X_true_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true_norm = np.zeros( (4400, 8, 9000) )\n",
    "\n",
    "for i in range (4400) :\n",
    "    X_true_norm[i,:,:] = normalisation( X_true_reshape[i,:,:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for X_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( X_true_norm )  # our prediction\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) # visualizing the coherence of our prediction\n",
    "sns.heatmap( y_pred, cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output for the challenge & decision rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission = pd.read_csv('y_benchmark.csv') # excample of prediction\n",
    "y_submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y_pred.shape[0]):\n",
    "    for j in range(y_pred.shape[1]):\n",
    "        if y_pred[i,j]>0.5:          \n",
    "            \n",
    "            y_submission.iloc[i,j+1]=1\n",
    "        else :\n",
    "            y_submission.iloc[i,j+1]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) # visualizing the  prediction\n",
    "sns.heatmap(y_submission.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "y_submission.to_csv('essai de prediction2.csv' ,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##########   PERSONNAL NOTES, DO NOT READ####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNALS_NAME = [\n",
    "    \"AbdoBelt\",\n",
    "    \"AirFlow\",\n",
    "    \"PPG\",\n",
    "    \"ThorBelt\",\n",
    "    \"Snoring\",\n",
    "    \"SPO2\",\n",
    "    \"C4A1\",\n",
    "    \"O2A1\",\n",
    "]\n",
    "\n",
    "\n",
    "def extract_events_from_binary_mask(binary_mask, fs=1):\n",
    "    binary_mask = np.array([0] + binary_mask.tolist() + [0])\n",
    "    diff_data = np.diff(binary_mask)\n",
    "    starts = np.where(diff_data == 1)[0] / fs\n",
    "    ends = np.where(diff_data == -1)[0] / fs\n",
    "\n",
    "    assert len(starts) == len(ends)\n",
    "    events = []\n",
    "    for i, _ in enumerate(starts):\n",
    "        events += [(starts[i], ends[i])]\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def visualize_signal_and_event(X, mask, signals_name=SIGNALS_NAME, signal_freq=100):\n",
    "    n_signal = X.shape[0]\n",
    "    fig, axs = plt.subplots(n_signal, sharex=True)\n",
    "    events = extract_events_from_binary_mask(mask)\n",
    "    for i in range(n_signal):\n",
    "        axs[i].plot(np.arange(0, X[i].shape[0]) / signal_freq, X[i])\n",
    "        axs[i].set_ylabel(signals_name[i])\n",
    "        for elt in events:\n",
    "            axs[i].axvspan(elt[0], elt[1], color='red', alpha=0.3)\n",
    "    plt.xlim(0, X[0].shape[0]/ signal_freq)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualise_index(idx, data_h5, masks, N_signals=8):\n",
    "    x = data_h5['data'][idx, 2:]\n",
    "    x = x.reshape(N_signals, -1)\n",
    "    visualize_signal_and_event(x, np.array(masks[idx, 1:]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import h5py\n",
    "    PATH_TO_TRAINING_DATA = \"C:\\\\Users\\\\pierr\\\\REPERTOIRE_PROJETS_DATA\\\\DREEM_PROJECT\\\\X_train.h5\"\n",
    "    PATH_TO_TRAINING_TARGET = \"C:\\\\Users\\\\pierr\\\\REPERTOIRE_PROJETS_DATA\\\\DREEM_PROJECT\\\\y_train.csv\"\n",
    "    h5_file = h5py.File(PATH_TO_TRAINING_DATA)\n",
    "    mask = np.array(pd.read_csv(PATH_TO_TRAINING_TARGET))\n",
    "    visualise_index(18, h5_file, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
